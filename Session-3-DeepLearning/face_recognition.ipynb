{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Recognition System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we build a Face Recognition System based on LFW Face dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='assets/task.png'>\n",
    "\n",
    "\n",
    "## What we are trying to do:\n",
    "\n",
    "\n",
    "<img src='assets/pre.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.animation as animation\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as utils\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "seed=123456789\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_lfw_people\n",
    "lfw_people = fetch_lfw_people(data_home='data/',min_faces_per_person=100, resize=1)\n",
    "\n",
    "images = lfw_people.images\n",
    "targets = lfw_people.target\n",
    "target_names = lfw_people.target_names\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, targets, test_size=0.4, random_state=seed, stratify=targets)\n",
    "X_train = torch.from_numpy(X_train)\n",
    "X_test = torch.from_numpy(X_test)\n",
    "y_train=torch.from_numpy(y_train)\n",
    "y_test = torch.from_numpy(y_test)\n",
    "\n",
    "X_train = X_train[:, None, :, :]\n",
    "X_test = X_test[:, None, :, :]\n",
    "\n",
    "train_data = DataLoader(utils.TensorDataset(X_train, y_train), batch_size=8, shuffle=True, num_workers=2)\n",
    "test_data = DataLoader(utils.TensorDataset(X_test, y_test),batch_size=8, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceNet(nn.Module):\n",
    "    def __init__(self, img_h, img_w):\n",
    "        super(FaceNet, self).__init__()\n",
    "        self.num_maxpools = 2\n",
    "        self.img_h = img_h\n",
    "        self.img_w = img_w\n",
    "        self.num_flatten_units = (self.img_h // (2**self.num_maxpools)) * (self.img_w // (2**self.num_maxpools))\n",
    "        self.conv1 = nn.Conv2d(in_channels = 1,\n",
    "                               out_channels = 20,\n",
    "                               kernel_size = 5,\n",
    "                               padding = 2\n",
    "                              )\n",
    "        self.conv2 = nn.Conv2d(in_channels = 20,\n",
    "                               out_channels = 50,\n",
    "                               kernel_size = 5,\n",
    "                               padding = 2\n",
    "                              )\n",
    "        self.maxpool = nn.MaxPool2d(2,2)\n",
    "        self.fc1 = nn.Linear(self.num_flatten_units * 50, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        f1_map = x\n",
    "        x = self.maxpool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        f2_map = x\n",
    "        x = self.maxpool(x)\n",
    "        x = x.view(-1, self.num_flatten_units * 50)\n",
    "        x = F.leaky_relu(self.fc1(x), 0.2)\n",
    "        x = self.fc2(x)\n",
    "        return f1_map, f2_map, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, dataset):\n",
    "    model = model.eval()\n",
    "    model = model.to(DEVICE)\n",
    "    running_loss = 0\n",
    "    total_len = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_set in dataset:\n",
    "            inputs = batch_set[0].to(DEVICE)\n",
    "            outputs = batch_set[1].to(DEVICE)\n",
    "            \n",
    "            _, _, predictions = model(inputs)\n",
    "            \n",
    "            loss = CE_LOSS(predictions, outputs)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            total_len += len(inputs)\n",
    "            \n",
    "            _, predicted = torch.max(predictions.data, 1)\n",
    "            correct += (predicted == outputs).sum().item()\n",
    "            \n",
    "    return running_loss/total_len, correct/total_len * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "CE_LOSS = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "EPOCHS = 5\n",
    "LR = (1e-05)/2\n",
    "\n",
    "img_shape = (125, 94)\n",
    "model = FaceNet(*img_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_dict = {'train':[], 'index':[]}\n",
    "optimizer = torch.optim.Adam(model.parameters(), LR)  \n",
    "\n",
    "print(\"Training Started\")\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "    for iteration, batch_set in enumerate(train_data):\n",
    "\n",
    "        model = model.train()\n",
    "\n",
    "        inputs = batch_set[0].to(DEVICE)\n",
    "        outputs = batch_set[1].to(DEVICE)\n",
    "\n",
    "        _, _, predictions = model(inputs)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss = CE_LOSS(predictions, outputs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss, train_accuracy = test(model, train_data)\n",
    "\n",
    "    print('{:*^75}'.format(''))\n",
    "    print(datetime.datetime.now())\n",
    "    print(\"Epoch: {}-> Train Loss: {:.4f}, Train Accuracy: {:.4f}\".format(i+1, train_loss, train_accuracy))\n",
    "    print('{:*^75}'.format(''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, test_accuracy = test(model, test_data)\n",
    "print(\"Test Accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Use Model (Make Predictions)\n",
    "\n",
    "We can recognize the face using face image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, img):\n",
    "    model = model.eval()\n",
    "    img = img.to(DEVICE)\n",
    "    model = model.to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        _, _, prediction = model(img)\n",
    "        _, prediction = torch.max(prediction.data, 1)\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Taking Face Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = X_test[93].squeeze(0).numpy().astype(int)\n",
    "plt.imshow(test_img, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Doing Face Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = predict(model, X_test[93].unsqueeze(0))\n",
    "print(\"Predicted Person: {}\".format(target_names[prediction.item()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
