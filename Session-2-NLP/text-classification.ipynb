{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam Detection Using Naives Bayes Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import matplotlib.pyplot as plt # plotting\n",
    "import nltk # for natural language processing tasks\n",
    "import numpy as np # numerical computing library\n",
    "import pandas as pd # for data visualization, preprocessing and wrangling\n",
    "import seaborn as sns # for graphing and visualization\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import various functions and classes of sklearn for our propose\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.utils.multiclass import unique_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training data\n",
    "# data is obtained from kaggle\n",
    "# kaggla dataset link: https://www.kaggle.com/uciml/sms-spam-collection-dataset\n",
    "data = pd.read_csv('data/spam.csv')\n",
    "\n",
    "data['target'] = np.where(data['target']=='spam',1, 0)\n",
    "print('No of rows:', len(data))\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peek into Spam Messages and Non-spam Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['target'] == 0].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['target'] == 1].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data into Training and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the dataset into training and test data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data['text'], \n",
    "                                                    data['target'], \n",
    "                                                    random_state=0)\n",
    "print(\"Training data shape:\", X_train.shape)\n",
    "print(\"Testing data shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract features\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 2)).fit(X_train)\n",
    "X_train_vectorized = vectorizer.transform(X_train)\n",
    "X_train_vectorized.toarray().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Naive Bayes model\n",
    "model = MultinomialNB(alpha=0.1)\n",
    "model.fit(X_train_vectorized, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions on Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict y values for test dataset using the model we created\n",
    "predictions = model.predict(vectorizer.transform(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see accuracy in the testing set\n",
    "print(\"Accuracy:\", 100 * sum(predictions == Y_test) / len(predictions), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See performance on real life examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recent official emails\n",
    "model.predict(vectorizer.transform(\n",
    "    [\n",
    "        \"Dear ABC, Thank you very much for sharing these files with us. I will request your help if need be. Regards, XYZ\",\n",
    "        \"Hi ABC, Thanks for putting together the note on admin code. Itâ€™s great first draft! It covers many important aspects I wanted to have a good understanding about!\",\n",
    "        \"Dear ABC, Thanks for the kind reply. The paper seems very interesting, will discuss more when we meet. Referring to our previous conversation, it would be great to know about your work on mapping the administrative units. Furthermore, we would appreciate knowing about the depth of administrative level mapping and the methodology. I have copied ABC DEF (GHI) in our team who is working on a similar task. ABC can reflect on the technical perspectives as the conversation progress. We are looking forward to hearing from you and mutually benefit from the data if your convenience permits. Best regards, XYZ\",\n",
    "        \"Hi ABC and DEF, A gentle reminder that we're very interested in hearing more about your comparisons between the HRSL dataset, WorldPop and other similar datasets. We're planning on doing a small desk review specific to Nepal when we have time and would appreciate the opportunity to start from where you all left off. We are of course more than happy to keep any unpublished research findings you share internal to the World Bank, and share back the results of our review.\",\n",
    "        \"Dear all â€“ hereâ€™s a room for us if you need it tomorrow morning. Best regards â€“ XYZ\",\n",
    "    ])\n",
    "            )              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recent personal emails\n",
    "model.predict(vectorizer.transform(\n",
    "    [\n",
    "        \"Thank you, ABC. Can you also share your updated GitHub and LinkedIn profile? It helps to have personal/college projects in GitHub with proper documentation. As you are a fresher, employers would be willing to see your personal/college projects. Also, share a competitive programming profile if any.\",\n",
    "        \"XYZ, That would be great! Please do let me know â€” I am an avid learner as you know and I LOVE attending lecture series and learning new things. Very much appreciate your offer. Thank you!! See you very soon indeed. -DEF-\",\n",
    "        \"Hi ABC, I wish I was in Kathmandu so that we could have in-person discussion. However, will you be available for hangout call sometime next week? Let me know of your availability. We can talk more about your interest and future plans and discuss the options. -XYZ\",\n",
    "        \"Hi yâ€™all, Making quick introductions between python + QGIS Atlas lovers in Kathmandu. ABC, XYZ is looking at your code now and seems pretty comfortable with it. I told him he can write you with any questions â€” hope thatâ€™s OK. Iâ€™ll buy you some momos by way of thanks. Best, DEF\",\n",
    "        \"Heyyy hiiiiii... Long time... Remember me? ðŸ˜ŠðŸ˜‚ How are you? How's it going there...? What are you upto? :)\",\n",
    "    ])\n",
    "            ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  recent spam email in my official mail\n",
    "# recent personal emails\n",
    "model.predict(vectorizer.transform(\n",
    "    [\n",
    "        \"get free discount in plane tickets\",\n",
    "        \"free recharge card offer\",\n",
    "        \"girls are waiting to chat with you\",\n",
    "        \"1-month unlimited calls offer Activate now\",\n",
    "        \"congratulation, you became today's lucky winner\",\n",
    "        \"Jelie wants your phone number\",\n",
    "        \n",
    "    ])\n",
    "            ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contrasts\n",
    "model.predict(vectorizer.transform(\n",
    "    [\n",
    "        \"Jelie wants your email\",\n",
    "        \"can you please share your phone number?\"\n",
    "    ])\n",
    "            ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddddD"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BallotClassification",
   "language": "python",
   "name": "ballot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
